<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>vLLM框架原理——PagedAttention | Lan&#39;s Notebook</title>
<meta name="description" content="">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel="shortcut icon" href="https://yerayl.github.io//favicon.ico?v=1745483680487">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="stylesheet" href="https://unpkg.com/papercss@1.6.1/dist/paper.min.css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://yerayl.github.io//styles/main.css">


<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>


<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />


  </head>
  <body>
  
    <nav class="navbar border fixed split-nav">
  <div class="nav-brand">
    <h3><a href="https://yerayl.github.io/">Lan&#39;s Notebook</a></h3>
  </div>
  <div class="collapsible">
    <input id="collapsible1" type="checkbox" name="collapsible1">
    <button>
      <label for="collapsible1">
        <div class="bar1"></div>
        <div class="bar2"></div>
        <div class="bar3"></div>
      </label>
    </button>
    <div class="collapsible-body">
      <ul class="inline">
        
          <li>
            
              <a href="/" class="menu">
                首页
              </a>
            
          </li>
        
          <li>
            
              <a href="/archives" class="menu">
                归档
              </a>
            
          </li>
        
          <li>
            
              <a href="/tags" class="menu">
                标签
              </a>
            
          </li>
        
          <li>
            
              <a href="/post/about" class="menu">
                关于
              </a>
            
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div id="top" class="row site">
      <div class="sm-12 md-8 col">
        <div class="paper">
          <article class="article">
            <h1>vLLM框架原理——PagedAttention</h1>
            <p class="article-meta">
              2023-08-11
              
                <a href="https://yerayl.github.io/tag/XQIChG8bY/" class="badge secondary">
                  大语言模型
                </a>
              
            </p>
            
              <img src="https://raw.githubusercontent.com/vllm-project/vllm/main/docs/source/assets/logos/vllm-logo-text-light.png" alt="vLLM框架原理——PagedAttention">
            
            <div class="post-content" v-pre>
              <h2 id="简介">简介</h2>
<p>vLLM是一个开源的大模型推理加速框架，通过PagedAttention高效地管理attention中缓存的张量，实现了比HuggingFace Transformers高24倍的吞吐量。</p>
<h2 id="pagedattention">PagedAttention</h2>
<p>作者发现大模型推理的性能瓶颈主要来自于内存。一是自回归过程中缓存的K和V张量非常大，在LLaMA-13B中，单个序列输入进来需要占用1.7GB内存。二是内存占用是动态的，取决于输入序列的长度。由于碎片化和过度预留，现有的系统浪费了60%-80%的内存。</p>
<p>PagedAttention灵感来自于操作系统中<strong>虚拟内存</strong>和<strong>分页</strong>的经典思想，它可以允许在非连续空间立存储连续的KV张量。具体来说，<strong>PagedAttention把每个序列的KV缓存进行了分块，每个块包含固定长度的token</strong>，而在计算attention时可以高效地找到并获取那些块。</p>
<figure data-type="image" tabindex="1"><img src="https://vllm.ai/assets/figures/annimation0.gif" alt="KV缓存分片的过程" title="KV缓存分片的过程" loading="lazy"></figure>
<p>每个固定长度的块可以看成虚拟内存中的页，token可以看成字节，序列可以看成进程。那么通过一个块表就可以将连续的逻辑块映射到非连续的物理块，而物理块可以根据新生成的token按需分配。</p>
<figure data-type="image" tabindex="2"><img src="https://vllm.ai/assets/figures/annimation1.gif" alt="通过PagedAttention生成序列的过程" title="通过PagedAttention生成的过程" loading="lazy"></figure>
<p>所以序列在分块之后，只有最后一个块可能会浪费内存（实际中浪费的内存低于4%）。高效利用内存的好处很明显：系统可以在一个batch中同时输入更多的序列，提升GPU的利用率，显著地提升吞吐量。</p>
<p>PagedAttention的另外一个好处是<strong>高效内存共享</strong>。例如，在并行采样的时候，一个prompt需要生成多个输出序列。这种情况下，对于这个prompt的计算和内存可以在输出序列之间共享。</p>
<figure data-type="image" tabindex="3"><img src="https://vllm.ai/assets/figures/annimation2.gif" alt="并行采样的例子" title="并行采样的例子" loading="lazy"></figure>
<p>通过块表可以自然地实现内存共享。类似进程之间共享物理页，在PagedAttention中的不同序列通过将逻辑块映射到一样的物理块上可以实现共享块。为了确保安全共享，PagedAttention跟踪物理块的引用计数，并实现了<strong>Copy-on-Write</strong>机制。<br>
<img src="https://vllm.ai/assets/figures/annimation3.gif" alt="同一个输入采样生成多个输出的例子" title="同一个输入采样生成多个输出的例子" loading="lazy"></p>
<p>内存共享减少了55%内存使用量，大大降低了采样算法的内存开销，同时提升了高达2.2倍的吞吐量。</p>
<p><a href="https://lmsys.org/">LMSYS</a>早期使用基于Huggingface Transformers的服务后端代码：https://github.com/lm-sys/FastChat/blob/main/fastchat/serve/model_worker.py</p>
<p>使用vLLM部署的代码（FastChat-vLLM：FastChat作为模型聊天服务前端，vLLM作为推理后端）：https://github.com/lm-sys/FastChat/blob/main/fastchat/serve/vllm_worker.py</p>
<p>吞吐量测试的代码：https://github.com/lm-sys/FastChat/blob/main/fastchat/serve/test_throughput.py</p>
<p>早期的测试结果显示vLLM提升了30倍以上的吞吐量。vLLM的使用也大大降低了运营成本，LMSYS使用vLLM减少了50%gpu数量。同时每天可以平均处理30K请求，峰值为60K，证明了vLLM的鲁棒性。</p>
<h2 id="快速使用"><a href="https://vllm.readthedocs.io/en/latest/getting_started/quickstart.html">快速使用</a></h2>
<p>安装vLLM：</p>
<pre><code class="language-shell">$ pip install vllm
</code></pre>
<p>导入vLLM并在Python脚本中使用LLM类：</p>
<pre><code class="language-python">from vllm import LLM

prompts = [&quot;Hello, my name is&quot;, &quot;The capital of France is&quot;]  # Sample prompts.
llm = LLM(model=&quot;lmsys/vicuna-7b-v1.3&quot;)  # Create an LLM.
outputs = llm.generate(prompts)  # Generate texts from the prompts.
</code></pre>
<p>要使用vLLM进行在线服务，可以通过以下方式启动与OpenAI api兼容的服务:</p>
<pre><code class="language-shell">$ python -m vllm.entrypoints.openai.api_server --model lmsys/vicuna-7b-v1.3
</code></pre>
<p>可以使用与OpenAI API相同的格式查询服务器:</p>
<pre><code class="language-shell">$ curl http://localhost:8000/v1/completions \
    -H &quot;Content-Type: application/json&quot; \
    -d '{
        &quot;model&quot;: &quot;lmsys/vicuna-7b-v1.3&quot;,
        &quot;prompt&quot;: &quot;San Francisco is a&quot;,
        &quot;max_tokens&quot;: 7,
        &quot;temperature&quot;: 0
    }'
</code></pre>
<p>[1] <a href="https://vllm.ai/">vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention</a></p>

            </div>
          </article>
        </div>
        <div class="paper" data-aos="fade-in">
          
        </div>
        
      </div>

      <div class="sm-12 md-4 col sidebar">
  <div class="paper info-container">
    <img src="https://yerayl.github.io//images/avatar.png?v=1745483680487" class="no-responsive avatar">
    <div class="text-muted"></div>
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
  </div>
  <div class="paper">
    <div class="sidebar-title">
      最新文章
    </div>
    <div class="row">
      <ul>
        
          
            <li>
              <a href="https://yerayl.github.io/post/zhuan-ti-wen-de-zhi-hui/">[转] 提问的智慧</a>
            </li>
          
        
          
            <li>
              <a href="https://yerayl.github.io/post/zi-wo-xing-wei-qing-xu-diao-kong/">自我行为、情绪调控</a>
            </li>
          
        
          
            <li>
              <a href="https://yerayl.github.io/post/shi-jie-yu-ren-lei-xing-wei-mo-xing-zhu-li-you-xi-chuang-yi-gou-si/">世界与人类行为模型助力游戏创意构思</a>
            </li>
          
        
          
            <li>
              <a href="https://yerayl.github.io/post/icpr-2024-leveraging-persistent-homology-for-differential-diagnosis-of-mild-cognitive-impairment/">[ICPR 2024 ] Leveraging Persistent Homology for Differential Diagnosis of Mild Cognitive Impairment</a>
            </li>
          
        
          
            <li>
              <a href="https://yerayl.github.io/post/icml-2024-less-is-more-on-the-over-globalizing-problem-in-graph-transformers/">[ICML 2024] Less is More: on the Over-Globalizing Problem in Graph Transformers</a>
            </li>
          
        
          
            <li>
              <a href="https://yerayl.github.io/post/fu-xi-yi-xia-ge-la-mu-shi-mi-te-zheng-jiao-hua/">Gram-Schmidt Process</a>
            </li>
          
        
          
            <li>
              <a href="https://yerayl.github.io/post/dan-ci-zhong-de-you-xie-fu-yin-wei-shi-me-xu-yao-shuang-xie-shi-me-shi-hou-gai-shuang-xie-shuang-xie-ru-he-ying-xiang-fa-yin/">单词中的有些辅音为什么需要双写？什么时候该双写？双写如何影响发音？</a>
            </li>
          
        
          
            <li>
              <a href="https://yerayl.github.io/post/cikm-2024-contrasformer-a-brain-network-contrastive-transformer-for-neurodegenerative-condition-identification/">[CIKM 2024] Contrasformer: A Brain Network Contrastive Transformer for Neurodegenerative Condition Identification</a>
            </li>
          
        
          
            <li>
              <a href="https://yerayl.github.io/post/icml-2024-learning-high-order-relationships-of-brain-regions/">[ICML 2024] Learning High-Order Relationships of Brain Regions</a>
            </li>
          
        
          
            <li>
              <a href="https://yerayl.github.io/post/isbi-2024-brainnetdiff-generative-ai-empowers-brain-network-generation-via-multimodal-diffusion-model/">[ISBI 2024] BrainNetDiff: Generative AI Empowers Brain Network Generation via Multimodal Diffusion Model</a>
            </li>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </div>
  <div class="paper">
    <div class="sidebar-title">
      标签列表
    </div>
    <div class="row">
      
        <a href="https://yerayl.github.io/tag/UaQYYkSjoD/" class="badge warning">
          脑网络
        </a>
      
        <a href="https://yerayl.github.io/tag/aFf4yKHyI4/" class="badge warning">
          数据分析方法
        </a>
      
        <a href="https://yerayl.github.io/tag/ScYh_jFIq8/" class="badge secondary">
          图神经网络
        </a>
      
        <a href="https://yerayl.github.io/tag/V81nyARvlV/" class="badge ">
          线性代数
        </a>
      
        <a href="https://yerayl.github.io/tag/MiVHjfdfx5/" class="badge secondary">
          扩散模型
        </a>
      
        <a href="https://yerayl.github.io/tag/0DR2nRVm11/" class="badge secondary">
          类脑
        </a>
      
        <a href="https://yerayl.github.io/tag/l9DbS9x0D0/" class="badge warning">
          LaTex
        </a>
      
        <a href="https://yerayl.github.io/tag/32LisoKWZc/" class="badge warning">
          认知神经科学
        </a>
      
        <a href="https://yerayl.github.io/tag/XQIChG8bY/" class="badge secondary">
          大语言模型
        </a>
      
        <a href="https://yerayl.github.io/tag/qSbxg_yyX/" class="badge warning">
          知识图谱
        </a>
      
    </div>
  </div>
  <div class="paper">
    <a href="https://yerayl.github.io/" target="_blank">Home</a> | <a class="rss" href="https://yerayl.github.io//atom.xml" target="_blank">RSS</a>
  </div>
</div>


    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>

<script type="application/javascript">

AOS.init();

hljs.initHighlightingOnLoad()

</script>




  </body>
</html>
